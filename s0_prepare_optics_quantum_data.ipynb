{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc1ab20d",
   "metadata": {},
   "source": [
    "这段代码从arXiv数据集中筛选出CS.cl领域的论文，提取标题、摘要和发布时间等核心信息，并进行文本清洗和标准化处理。最终将处理后的数据保存为PKL和JSON两种格式，为后续的领域概念挖掘和文本分析提供标准化的数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34f3f857-ce5c-4779-8209-ca0fb47340f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import linecache\n",
    "import time\n",
    "import jsonlines\n",
    "from datetime import datetime, date\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d360712-7cc0-4692-b5fc-69e2e6d2534d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub arxiv: 2848278\n",
      "cs.CL: 33892; Modified: 33892, Elapsed time: 33.86599063873291 seconds\n"
     ]
    }
   ],
   "source": [
    "starting_date = date(1990,1,1)\n",
    "start_time = time.time()\n",
    "\n",
    "#arxiv_folder='arxiv-snapshot'\n",
    "arxiv_folder=\"E:\\\\study\\\\research\\\\create_gynamic_edge\\\\concept corpus\"\n",
    "arxiv_json = os.path.join(arxiv_folder,\"arxiv-metadata-oai-snapshot.json\")\n",
    "\n",
    "arxiv_cs_original=[]\n",
    "arxiv_cs_modified=[]\n",
    "\n",
    "with jsonlines.open(arxiv_json, 'r') as f:\n",
    "    for id_of_abstract, line in enumerate(f):\n",
    "        if line['categories'] in ['cs.CL']:\n",
    "            arxiv_cs_original.append(line)  ## store the original one\n",
    "        \n",
    "            get_date = datetime.strptime(line['versions'][0]['created'], '%a, %d %b %Y %H:%M:%S %Z').date()\n",
    "            paper_time = (get_date - starting_date).days\n",
    "            arxiv_cs_modified.append([line['categories'],line['title'],line['abstract'],paper_time]) ## store modified one\n",
    "        \n",
    "elapsed_time = time.time() - start_time\n",
    "print(f\"sub arxiv: {id_of_abstract}\")\n",
    "print(f\"cs.CL: {len(arxiv_cs_original)}; Modified: {len(arxiv_cs_modified)}, Elapsed time: {elapsed_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ceb0317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files saved: arxiv_cs_modified.pkl and arxiv_cs_original.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 保存为pkl文件\n",
    "with open('arxiv_cs_style_modified.pkl', 'wb') as pkl_file:\n",
    "    pickle.dump(arxiv_cs_modified, pkl_file)\n",
    "\n",
    "# 保存为json文件\n",
    "with open('arxiv_cs_original.json', 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(arxiv_cs_original, json_file, ensure_ascii=False, indent=2)\n",
    "\n",
    "\n",
    "print(f\"Files saved: arxiv_cs_modified.pkl and arxiv_cs_original.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacfa9ab-f568-477b-b7de-cd3b77f7ffd3",
   "metadata": {},
   "source": [
    "## make only strings (title+abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2a75bed-b673-4e93-a7e0-775043857bab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ## (Read the modified metadata; [source, title, abstract, time])\n",
    "### (Make each article in string, under certain replacements)\n",
    "\n",
    "def get_single_article_string(article):\n",
    "    \n",
    "    curr_title=article[1] #'title'\n",
    "    curr_abstract=article[2] #'abstract'\n",
    "    \n",
    "    replace_pairs=[['\\n',' '],['-',' '],[' \\\" a','oa'],['\\\" a','ae'],['\\\"a','ae'],[' \\\" o','oe'],['\\\" o','oe'],['\\\"o','oe'],[' \\\" u','ue'],\n",
    "                   ['\\\" u','ue'],['\\\"u','ue'],[' \\' a','a'],[' \\' e','e'],[' \\' o','o'],[\"\\' \", \"\"],[\"\\'\", \"\"],['  ',' '],['  ',' ']]\n",
    "    \n",
    "    article_string=(curr_title +' '+ curr_abstract).lower()\n",
    "    \n",
    "    for rep_pair in replace_pairs:\n",
    "        #print(rep_pair)\n",
    "        \n",
    "        article_string=article_string.replace(rep_pair[0],rep_pair[1])\n",
    "        #print(article_string)\n",
    "        #print('\\n')\n",
    "    \n",
    "    return article_string\n",
    "\n",
    "\n",
    "def get_all_paper_strings(article_lists, folder_file):\n",
    "\n",
    "    if os.path.exists(os.path.join(folder_file,'arxiv_cs_paper_strings.pkl')):\n",
    "        with open(os.path.join(folder_file,'arxiv_cs_paper_strings.pkl'), \"rb\") as f:\n",
    "            arxiv_cs_paper_strings = pickle.load(f)\n",
    "            \n",
    "    else:\n",
    "        all_paper_strings=[]\n",
    "        cc=0\n",
    "        for id_of_paper in range(len(article_lists)):\n",
    "            cc+=1\n",
    "            #if (cc%3000)==0:\n",
    "                #print(str(cc)+'/'+str(len(article_lists)))\n",
    "\n",
    "            all_paper_strings.append(get_single_article_string(article_lists[id_of_paper]))\n",
    "\n",
    "        with open(os.path.join(folder_file,'arxiv_cs_paper_strings.pkl'), \"wb\") as f:\n",
    "            pickle.dump(all_paper_strings, f)\n",
    "    \n",
    "    return all_paper_strings    \n",
    "\n",
    "\n",
    "all_article_strings=get_all_paper_strings(arxiv_cs_modified,folder_file=\"E:\\\\study\\\\research\\\\create_gynamic_edge\\\\domain concepts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121b2bb6-2385-4112-b61b-b0f9f9f8494b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
