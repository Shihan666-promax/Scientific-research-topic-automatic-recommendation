{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbff53e8-c63a-4997-9761-b1018ca5c42e",
   "metadata": {},
   "source": [
    "##### improve domain concepts "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948907c6",
   "metadata": {},
   "source": [
    "这段代码对整合后的领域概念库进行了最终的精炼和优化。首先加载并去重所有概念，然后应用多层次过滤规则：去除包含通用词汇（如\"experiment\"、\"software\"）的概念，过滤特定开头词（如\"sophisticated\"、\"techniques\"）和结尾词（如\"illustrates\"、\"configuration\"），根据概念长度应用差异化过滤条件，并移除包含无意义短语组合的概念。最后删除原始文件，将优化后的高质量概念库重新保存为文本和PKL格式，确保最终概念集合的专业性和实用性。\n",
    "\n",
    "输入concept_seperate/all_concepts.pkl，包含所有合并后的概念列表，从34个分块概念文件整合而来。\n",
    "all_concepts.pkl \n",
    "    → 去重 → modify_full_concept_list \n",
    "    → 多层过滤 → improve_full_concept_list \n",
    "    → 输出到 full_domain_concepts.txt 和 improved_concepts_form_openalex.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1317372",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime, date\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from rake_nltk import Metric, Rake\n",
    "from collections import Counter\n",
    "import re\n",
    "from nltk.corpus import wordnet\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f05270b-b134-44e8-9bb8-5a5642b41755",
   "metadata": {},
   "source": [
    "##### store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf5d512d-2f85-4782-a665-cbc9a483a42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "concept_folder=\"concept_seperate\"\n",
    "## finish all \n",
    "all_concepts_file = os.path.join(concept_folder,'all_concepts.pkl')  # edges\n",
    "with open(all_concepts_file, \"rb\") as output_file:\n",
    "    all_concepts=pickle.load(output_file)\n",
    "    \n",
    "## remove repeated concepts\n",
    "unique_concepts = list(set(all_concepts))\n",
    "concepts_file='full_domain_concepts.txt' # rename 'full_concepts_form_openalex.txt'\n",
    "f = open(concepts_file, \"a\")\n",
    "for ii in range(len(unique_concepts)):\n",
    "    f.write(unique_concepts[ii]+'\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8433c817",
   "metadata": {},
   "source": [
    "##### read the concepts file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ad70368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06-12-2025 13:09:04; Concepts: 45761 \n"
     ]
    }
   ],
   "source": [
    " \n",
    "if os.path.exists(concepts_file):\n",
    "    # open the existing file for reading   \n",
    "    with open(concepts_file, \"r\") as f:\n",
    "        modify_full_concept_list = [line.rstrip() for line in f.readlines()]\n",
    "    \n",
    "    now_time = datetime.now()\n",
    "    formatted_time = now_time.strftime(\"%d-%m-%Y %H:%M:%S\")\n",
    "    print(\"{}; Concepts: {:d} \".format(formatted_time,len(modify_full_concept_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421f5569",
   "metadata": {},
   "source": [
    "##### filter concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "464d27f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concepts: 45761 ; Store: 41409; Remove: 4352 \n",
      "Elapsed time: 0.15 seconds\n",
      "06-12-2025 13:09:12; Concepts: 41409 \n"
     ]
    }
   ],
   "source": [
    "\n",
    "starting_time = time.time()\n",
    "\n",
    "filter_concept_any=['held','equal','dramatic','slowing','excited','occupied','charged','moving','layer','bi','argument','intuition','experiment','entirely','essentially','built','necessary','take','applicable','employ','visit','visited','herein','facilitates','varying','overlapping','addressed','issues','related','add','adds','dominant','preserve','preserves','preserved','stabilizing','match','manipulating','emerging','processed','data','continuously','analytically','argue','smoothly','connect','connects','connecting','software','matlab','toolbox','standard','industrial','technology','success','equipment','call','analogous','sense','persist','persists','throughout','calculated','useful','difficult','proved']\n",
    "\n",
    "filter_concept_start=['sophisticated','precise','remarkably','consists','gradually','simplified','complete','techniques','partially','presented','iterative','simple','preparation','clear','priori','ae','substantial','sending','protecting','optimized','optimize','optimizing','transmits','transmit','transmitting','transmitted','processing','pre','collect','collected','measured','varied','operating','algorithms','algorithm','robustly','shall','concept','packing','successful','apparent','apparently','readily','adapted','todays','imperfect','seemingly','seeming','shelf','properties','mechanism','phenomenon','behavior','theorem','procedure','usual','form','later','calculating','fundamentally']\n",
    "\n",
    "filter_concept_end=['illustrates','setup','consisting','set','capable','configuration','complete','borrowed','permit','utilizes','referred','refer','capable','pave','stem','preparation','scheme','optimizes','transmitted','transmit','operating','relate','packed','packing','platform','industry','adapt','adapts','adapted','arrangement','era','device','arrange','arranged','content','procedure','outlined','form','formed','followed','following','calculation']\n",
    "\n",
    "\n",
    "concept_to_remove_pair=['self']\n",
    "concept_to_keep_pair=['stabilization']\n",
    "\n",
    "conditioned_filter_concept_any5=['open']\n",
    "conditioned_filter_concept_any3=['driven','component']\n",
    "conditioned_filter_concept_any2=['probe','inspired','technique','open','added','transfer','connected','element','exchange']\n",
    "\n",
    "conditioned_filter_concept_start2=['doubly','probe']\n",
    "conditioned_filter_concept_end2=[]\n",
    "\n",
    "forbidden_continued_strings=['complete measurement','exact numerical','numerical technique','numerical method','complete set','pure entangled','quantum entangled','high fidelity']\n",
    "\n",
    "improve_full_concept_list=[]\n",
    "\n",
    "for one_concept in modify_full_concept_list:\n",
    "    \n",
    "    separated_words=one_concept.split()\n",
    "    do_remove=0\n",
    "    for word in separated_words:\n",
    "        if word in filter_concept_any:\n",
    "            do_remove=1\n",
    "            break\n",
    "        \n",
    "        if len(separated_words)<5: ## only for 5 words\n",
    "            if word in conditioned_filter_concept_any5:\n",
    "                do_remove=1\n",
    "                break\n",
    "\n",
    "            if len(separated_words)<=3:\n",
    "                if word in conditioned_filter_concept_any3:\n",
    "                    do_remove=1\n",
    "                    break\n",
    "                \n",
    "                if len(separated_words)==2: ## only for 2 words\n",
    "                    if word in conditioned_filter_concept_any2:\n",
    "                        do_remove=1\n",
    "                        break\n",
    "\n",
    "             \n",
    "    \n",
    "    if separated_words[0] in filter_concept_start:\n",
    "            do_remove=1\n",
    "    if separated_words[-1] in filter_concept_end:\n",
    "            do_remove=1\n",
    "                \n",
    "    if len(separated_words)==2:\n",
    "        if separated_words[0] in conditioned_filter_concept_start2: #check the start word \n",
    "            do_remove=1\n",
    "        if separated_words[-1] in conditioned_filter_concept_end2: #check the last word \n",
    "            do_remove=1\n",
    "\n",
    "    if do_remove==0:\n",
    "        for word in forbidden_continued_strings:\n",
    "            if word in one_concept:\n",
    "                do_remove=1\n",
    "                break\n",
    "\n",
    "    if do_remove==0:\n",
    "        improve_full_concept_list.append(one_concept)\n",
    "        \n",
    "print(\"Concepts: {:d} ; Store: {:d}; Remove: {:d} \".format(len(modify_full_concept_list), len(improve_full_concept_list),len(modify_full_concept_list)-len(improve_full_concept_list)))\n",
    "elapsed_time = time.time() - starting_time\n",
    "print(\"Elapsed time: {:.2f} seconds\".format(elapsed_time))\n",
    "\n",
    "now_time =  datetime.now()\n",
    "formatted_time = now_time.strftime(\"%d-%m-%Y %H:%M:%S\")\n",
    "print(\"{}; Concepts: {:d} \".format(formatted_time,len(improve_full_concept_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736ce8e2",
   "metadata": {},
   "source": [
    "##### restore the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cd82ff3-5ffd-4988-83cf-d59fccf32e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "txt has been deleted.\n",
      "re-create text and store information.\n",
      "06-12-2025 13:09:19; Concepts: 41409 \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Delete the orginal txt and re-create a new one with the improved concepts \n",
    "if os.path.exists(concepts_file):\n",
    "    os.remove(concepts_file)\n",
    "    print(\"txt has been deleted.\")\n",
    "\n",
    "    # re-Create the text file  \n",
    "    f = open(concepts_file, \"a\")\n",
    "    for ii in range(len(improve_full_concept_list)):\n",
    "        f.write(improve_full_concept_list[ii]+'\\n')\n",
    "    f.close()\n",
    "    print(\"re-create text and store information.\")  \n",
    "else:\n",
    "    f = open(concepts_file, \"a\")\n",
    "    for ii in range(len(improve_full_concept_list)):\n",
    "        f.write(improve_full_concept_list[ii]+'\\n')\n",
    "    f.close()\n",
    "    print(\"create text and store information.\")\n",
    "    \n",
    "now_time = datetime.now()\n",
    "formatted_time = now_time.strftime(\"%d-%m-%Y %H:%M:%S\")\n",
    "print(\"{}; Concepts: {:d} \".format(formatted_time,len(improve_full_concept_list)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55cc750e",
   "metadata": {},
   "source": [
    "##### additionally, store a pkl file (as a backup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1987ab1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "concepts_path_pkl='improved_concepts_form_openalex.pkl'\n",
    "with open(concepts_path_pkl, \"wb\") as output_file:\n",
    "    pickle.dump(improve_full_concept_list, output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
